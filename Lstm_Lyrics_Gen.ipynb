{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deep 3\n",
        "### Matan Leventer \n",
        "### Rom Amsili "
      ],
      "metadata": {
        "id": "CiMpZ3dZRqkq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-rEl1WpHgg6"
      },
      "outputs": [],
      "source": [
        "!pip install pretty_midi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PV6W2BD8nWsx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.word2vec import Text8Corpus\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import make_regression, make_classification\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torchvision\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import re\n",
        "from collections import defaultdict\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pretty_midi\n",
        "import torchvision\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import datasets, transforms\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbxkGZI90ZK1"
      },
      "outputs": [],
      "source": [
        "!rm -rf runs/*\n",
        "if not os.path.exists('./text8'):\n",
        "    !wget http://mattmahoney.net/dc/text8.zip\n",
        "    !unzip text8.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntpoVgQgtO8S"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjPb7iY9tQsz"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hW_1QiRdvVBd"
      },
      "outputs": [],
      "source": [
        "word2vec_size = 300\n",
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUyRFE280e5e"
      },
      "outputs": [],
      "source": [
        "corpus =Text8Corpus('./text8')\n",
        "word_model = Word2Vec(sentences=corpus, size=word2vec_size, window=5, min_count=1, workers=8)\n",
        "word_model.save(\"/content/drive/MyDrive/Deep_models/word2vec.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5XBeOEZ1HCe"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "word_model = KeyedVectors.load(\"/content/drive/MyDrive/Deep_models/word2vec.model\", mmap='r')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0wn0mNjcnVM"
      },
      "source": [
        "#Melody "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLmz1xHjndN1"
      },
      "outputs": [],
      "source": [
        "def get_midi_file_instrument_data(index_word, tpd, midi_file):\n",
        "    #  Features we want to extract:\n",
        "    start_time = index_word * tpd\n",
        "    end_time = start_time + tpd\n",
        "    matrix_chroma = midi_file.get_chroma(times = np.array([start_time,end_time])).mean(axis=1)\n",
        "    avarage_velocity= avarage_pitch=num_of_instruments= num_of_notes= has_drums = 0\n",
        "    for instrument in midi_file.instruments:\n",
        "        range = False  \n",
        "        for note in instrument.notes:\n",
        "            if start_time <= note.start:\n",
        "                if note.end <= end_time:\n",
        "                    if instrument.is_drum:\n",
        "                      has_drums = 1\n",
        "                    else:\n",
        "                      has_drums=0\n",
        "                    range = True\n",
        "                    num_of_notes += 1\n",
        "                    avarage_pitch = avarage_pitch + note.pitch\n",
        "                    avarage_velocity = avarage_velocity + note.velocity\n",
        "                else:  \n",
        "                    break\n",
        "        if range:\n",
        "          num_of_instruments += 1\n",
        "\n",
        "    if num_of_notes > 0:  \n",
        "        avarage_velocity = avarage_velocity / num_of_notes\n",
        "        avarage_pitch = avarage_pitch / num_of_notes\n",
        "        \n",
        "    final_features = np.concatenate((np.array([avarage_velocity, avarage_pitch, num_of_instruments,0,0, has_drums]),  matrix_chroma), axis=0) \n",
        "    return final_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fj3aMSqcVdO9"
      },
      "outputs": [],
      "source": [
        "def get_melody_path(artist,name):\n",
        "  output = ''\n",
        "  for word in artist.split(' '):\n",
        "      output += word + '_'\n",
        "  output += '-'\n",
        "  for word in name.split(' '):\n",
        "    output += word + '_'\n",
        "  return output[:-1]+'.mid'\n",
        "\n",
        "def prepare_text(df_path):\n",
        "  df1 = pd.read_csv(df_path,header=None)\n",
        "  df = df1.iloc[:,:3]\n",
        "  df.columns = ['Artist','Name','Lyrics']\n",
        "  df['Lyrics']= df['Lyrics'].apply(lambda x:' '.join(re.sub(r'[^\\w\\s]', '', x).split()))\n",
        "  text = df['Lyrics']\n",
        "  X = []\n",
        "  y = []\n",
        "  for j,row in df.iterrows():\n",
        "    lyrics = row['Lyrics'].split(' ')\n",
        "    midi_path = f\"/content/drive/MyDrive/midi_files/{get_melody_path(row['Artist'],row['Name'])}\"\n",
        "    try:\n",
        "      midi_data = pretty_midi.PrettyMIDI(midi_path)\n",
        "    except Exception as e:\n",
        "      continue\n",
        "    end_time = midi_data.get_end_time()\n",
        "    avg_time_per_word = end_time/len(lyrics)\n",
        "    beat_freq = np.mean([x - midi_data.get_beats()[i - 1] for i, x in enumerate(midi_data.get_beats())][1:])\n",
        "    len_instruments = len(midi_data.instruments)\n",
        "\n",
        "    for i in range(len(lyrics)-1):\n",
        "      word_melody = get_midi_file_instrument_data(i,avg_time_per_word,midi_data)\n",
        "      word_melody[3] = len_instruments\n",
        "      word_melody[4] = beat_freq\n",
        "      if word_model.wv.__contains__(lyrics[i]) and word_model.wv.__contains__(lyrics[i+1]):\n",
        "        X.append(torch.cat((torch.tensor(word_model.wv[lyrics[i]]),\n",
        "                            torch.from_numpy(word_melody).float()),0))\n",
        "        y.append(torch.tensor(word_model.wv[lyrics[i+1]]))\n",
        "  return X,y\n",
        "\n",
        "def prepare_test(df_path):\n",
        "  df1 = pd.read_csv(df_path,header=None)\n",
        "  df = df1.iloc[:,:3]\n",
        "  df.columns = ['Artist','Name','Lyrics']\n",
        "  df['Lyrics']= df['Lyrics'].apply(lambda x:' '.join(re.sub(r'[^\\w\\s]', '', x).split()))\n",
        "  text = df['Lyrics']\n",
        "  X = [[],[],[],[],[]]\n",
        "  y = []\n",
        "  for j,row in df.iterrows():\n",
        "    lyrics = row['Lyrics'].split(' ')\n",
        "    midi_path = f\"/content/drive/MyDrive/midi_files/{get_melody_path(row['Artist'],row['Name'])}\"\n",
        "    try:\n",
        "      midi_data = pretty_midi.PrettyMIDI(midi_path)\n",
        "    except Exception as e:\n",
        "      continue\n",
        "    end_time = midi_data.get_end_time()\n",
        "    avg_time_per_word = end_time/len(lyrics)\n",
        "    beat_freq = np.mean([x - midi_data.get_beats()[i - 1] for i, x in enumerate(midi_data.get_beats())][1:])\n",
        "    len_instruments = len(midi_data.instruments)\n",
        "    for i in range(len(lyrics)-1):\n",
        "      word_melody = get_midi_file_instrument_data(i,avg_time_per_word,midi_data)\n",
        "      word_melody[3] = len_instruments\n",
        "      word_melody[4] = beat_freq\n",
        "      X[j].append(torch.from_numpy(word_melody).float())\n",
        "  return X\n",
        "\n",
        "# X,y = prepare_text('lyrics_train_set.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tuH6-6jeDMj"
      },
      "outputs": [],
      "source": [
        "len(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgC33jPRSNCH"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=67)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_val)"
      ],
      "metadata": {
        "id": "QoHhFkvv2RfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6rtYDw8FjXE"
      },
      "outputs": [],
      "source": [
        "train_data = [[X_train[i], y_train[i]] for i in range(len(X_train))]\n",
        "val_data = [[X_val[i], y_val[i]] for i in range(len(X_val))]\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data, shuffle=False, batch_size=batch_size)\n",
        "valloader = torch.utils.data.DataLoader(val_data, shuffle=False, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzW-zKo9tht8"
      },
      "outputs": [],
      "source": [
        "# Define the model architecture\n",
        "class LstmModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size,dropout):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class GruModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size,dropout):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.gru(x)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "class LstmModel_fc(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size,dropout):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "        self.fc1 = nn.Linear(18, 100)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out_m = self.fc1(x[:,300:])\n",
        "        out = torch.cat((x[:,:300],out_m),1)\n",
        "        out, _ = self.lstm(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbAzghfvTZ6x"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer,name):\n",
        "    running_loss = 0.0\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X.float())\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if batch % 50 == 0 and batch!=0:\n",
        "            loss, current = loss.item(), batch * batch_size\n",
        "            writer.add_scalar(f'training/loss_{name}',\n",
        "                              running_loss / 50,\n",
        "                              epoch * len(dataloader) + batch)\n",
        "            running_loss =0.0\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btbf8tYQURO0"
      },
      "outputs": [],
      "source": [
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0)\n",
        "\n",
        "def sample(top10_dict):\n",
        "  top10_values = softmax(list(top10_dict.values()))\n",
        "  inx = np.argmax(np.random.multinomial(1,top10_values,1))\n",
        "  return list(top10_dict)[inx]\n",
        "\n",
        "def test(dataloader, model, loss_fn,name,topn):\n",
        "    running_loss = 0.0\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss = []\n",
        "    correct = 0\n",
        "    q=10\n",
        "    with torch.no_grad():\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            batch_pred = model(X.float())\n",
        "            loss = loss_fn(batch_pred, y)\n",
        "            test_loss.append(loss)\n",
        "            if q==0:\n",
        "              running_loss += loss.item()\n",
        "              writer.add_scalar(f'validation/loss_{name}',\n",
        "                                running_loss / 100,\n",
        "                                epoch * len(dataloader) + batch)\n",
        "              running_loss =0.0\n",
        "              q=10\n",
        "            q-=1\n",
        "            sample = 100\n",
        "            for i,pred in enumerate(batch_pred):\n",
        "              if i%sample == 0:\n",
        "                top10 = dict(word_model.most_similar(positive=[np.array(pred.cpu())], topn=topn))\n",
        "                true_word = word_model.wv.most_similar(positive=[np.array(y[i].cpu())], topn=1)[0][0]\n",
        "                if true_word in top10:\n",
        "                  correct+=1   #top10[y]\n",
        "                test_loss.append(loss_fn(pred, y))\n",
        "\n",
        "    test_loss = sum(test_loss)/len(test_loss)\n",
        "    size/=sample\n",
        "    correct /= size\n",
        "    print(f\"Accuracy: {(correct*100):>0.1f}%, Avg loss: {test_loss:>7f} \\n\")\n",
        "    return correct,test_loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "writer = SummaryWriter()"
      ],
      "metadata": {
        "id": "5NPA4SZJ39WC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorboard"
      ],
      "metadata": {
        "id": "Qos4fcsJ6NDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "e0F2g2f7DC5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Expirement with 2 architectures"
      ],
      "metadata": {
        "id": "sIwZ9EsGQ27e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "model_1 = LstmModel(input_size=word2vec_size+18, hidden_size=512, num_layers=2, output_size=word2vec_size,dropout=0).to(device)\n",
        "model_2 = LstmModel_fc(input_size=word2vec_size+100, hidden_size=512, num_layers=2, output_size=word2vec_size,dropout=0).to(device)"
      ],
      "metadata": {
        "id": "PBL4jSLP4Qi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsHgzUQEuB8B"
      },
      "outputs": [],
      "source": [
        "# Define the loss function and optimizer\n",
        "models = [\"model_1\",\"model_2\"]\n",
        "loss_list = []\n",
        "\n",
        "for i,model in enumerate([model_1,model_2]):\n",
        "  print(models[i])\n",
        "  validation_loss = 100.0\n",
        "  loss_fn = torch.nn.L1Loss()  \n",
        "  optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
        "  # Train the model\n",
        "  for epoch in range(4):\n",
        "      print(epoch)\n",
        "      # hidden = model.init_hidden(batch_size=1)\n",
        "      train(trainloader, model, loss_fn, optimizer,models[i])\n",
        "      acc,loss = test(valloader, model, loss_fn,models[i])\n",
        "      print('losses',validation_loss - loss,loss)\n",
        "      if validation_loss - loss < 0.000001:\n",
        "        print(\"Loss convergence\")\n",
        "        break\n",
        "      validation_loss  = loss\n",
        "      loss_list.append(loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc,loss = test(valloader, model_2, loss_fn,\"model_2\")\n"
      ],
      "metadata": {
        "id": "FXn0TZk5ZZcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okEwAq7nYjf3"
      },
      "source": [
        "#Genreate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1= torch.load('/content/drive/MyDrive/Deep3/model_1')\n",
        "model_2= torch.load('/content/drive/MyDrive/Deep3/model_2')"
      ],
      "metadata": {
        "id": "Fq8fhsr6ZxOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload test_set.csv!\n",
        "X_test,y_test = prepare_text('lyrics_test_set.csv')\n",
        "X_melody = prepare_test('lyrics_test_set.csv')"
      ],
      "metadata": {
        "id": "8cFbrAQnHbKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_words_in_song(path='lyrics_test_set.csv'):\n",
        "  df1 = pd.read_csv(path,header=None)\n",
        "  df = df1.iloc[:,:3]\n",
        "  df.columns = ['Artist','Name','Lyrics']\n",
        "  df['Lyrics']= df['Lyrics'].apply(lambda x:' '.join(re.sub(r'[^\\w\\s]', '', x).split()))\n",
        "  text = df['Lyrics']\n",
        "  len_lyrics = {}\n",
        "  for j,row in df.iterrows():\n",
        "    lyrics = row['Lyrics'].split(' ')\n",
        "    len_lyrics[j] = 0\n",
        "    for i in range(len(lyrics)-1):\n",
        "      if word_model.wv.__contains__(lyrics[i]) and word_model.wv.__contains__(lyrics[i+1]):\n",
        "        len_lyrics[j] += 1\n",
        "  return len_lyrics\n",
        "count_words_in_song()"
      ],
      "metadata": {
        "id": "IlnT9TlvbAMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSoYkyK7RupY"
      },
      "outputs": [],
      "source": [
        "model = model_1\n",
        "N = 298\n",
        "m=0\n",
        "# first_word = word_model.wv.most_similar(positive=[X_test[N][:300].cpu().detach().numpy().squeeze()], topn=1)[0][0]\n",
        "first_word = word_model.wv['deep']\n",
        "next = \"\\x1B[4m\"+'Verse 1:\\n'+\"\\x1B[0m\"+ 'deep' + \" \"\n",
        "gen = torch.cat((torch.tensor(first_word).to(device),X_melody[m][0].to(device)),0)\n",
        "new_line=random.randint(3, 6)\n",
        "lines=0\n",
        "Chorus = ['',False]\n",
        "for i in range(150):\n",
        "  new_line-=1\n",
        "  if new_line==0:\n",
        "    new_line=random.randint(3, 6)\n",
        "    next+='\\n'\n",
        "    if Chorus[1]:\n",
        "      Chorus[0] += '\\n'\n",
        "    lines +=1\n",
        "    if lines == 6:\n",
        "      next+=\"\\x1B[4m\"+'\\nCourse:\\n'+\"\\x1B[0m\" \n",
        "      Chorus[1] = True\n",
        "    if lines == 9:\n",
        "      next+=\"\\x1B[4m\"+'\\nVerse 2:\\n'+\"\\x1B[0m\" \n",
        "      Chorus[1] = False\n",
        "    if lines == 15:\n",
        "      next+=\"\\x1B[4m\"+'\\nChorus:\\n'+\"\\x1B[0m\"+Chorus[0] \n",
        "      break\n",
        "  word = model(gen[None].to(device))\n",
        "  gen = torch.cat((word.squeeze(),X_melody[m][i+1].to(device)),0)\n",
        "  if Chorus[1]:\n",
        "    word = sample(dict(word_model.wv.most_similar(positive=[word.cpu().detach().numpy().squeeze()], topn=10))) + ' '\n",
        "    next += word\n",
        "    Chorus[0] += word \n",
        "  else:\n",
        "    next += sample(dict(word_model.wv.most_similar(positive=[word.cpu().detach().numpy().squeeze()], topn=10))) + ' '\n",
        "print(next)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Comparison\n",
        "## expirement with different hyperparameters"
      ],
      "metadata": {
        "id": "ARZjBqHj5NSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_model= ['Lstm','Gru']\n",
        "list_batch_size = [64,128]\n",
        "list_dropout = [0 ,0.2]\n",
        "list_hidden_size = [256,512]\n",
        "list_num_layers = [2 ,8]"
      ],
      "metadata": {
        "id": "19IAyzJe8ndK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_dict = {}\n",
        "loss_dict = {}\n",
        "for m in list_model:\n",
        "  for hidden in list_hidden_size:\n",
        "    for num_layers in list_num_layers:\n",
        "      for dropout in list_dropout:\n",
        "        for batch_size in list_batch_size:\n",
        "          validation_loss = 100.0\n",
        "          if m == 'Lstm':\n",
        "            model = LstmModel(input_size=word2vec_size+18, hidden_size=hidden, num_layers=num_layers, output_size=word2vec_size,dropout=dropout).to(device)\n",
        "          else:\n",
        "            model = GruModel(input_size=word2vec_size+18, hidden_size=hidden, num_layers=num_layers, output_size=word2vec_size,dropout=dropout).to(device)\n",
        "          trainloader = torch.utils.data.DataLoader(train_data, shuffle=False, batch_size=batch_size)\n",
        "          valloader = torch.utils.data.DataLoader(val_data, shuffle=False, batch_size=batch_size)\n",
        "          loss_fn = torch.nn.L1Loss()  \n",
        "          optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
        "          name = f'{m}_{hidden}_{num_layers}_{dropout}_{batch_size}'\n",
        "          loss_list = []\n",
        "          for epoch in range(4):\n",
        "              train(trainloader, model, loss_fn, optimizer,name)\n",
        "              acc,loss = test(valloader, model, loss_fn,name)\n",
        "              if validation_loss - loss <0.01:\n",
        "                print(\"Loss convergence\")\n",
        "                break\n",
        "              validation_loss  = loss\n",
        "              loss_list.append(loss)\n",
        "          loss_dict[f'{m}_{hidden}_{num_layers}_{dropout}_{batch_size}'] = loss_list\n",
        "          torch.save(model,f'/content/drive/MyDrive/Deep3/{name}')\n",
        "          print(f'{name} finished')"
      ],
      "metadata": {
        "id": "swVw5txKSvvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_acc = {}\n",
        "for m in list_model:\n",
        "  for hidden in list_hidden_size:\n",
        "    for num_layers in list_num_layers:\n",
        "      for dropout in list_dropout:\n",
        "        for batch_size in list_batch_size:\n",
        "            name = f'{m}_{hidden}_{num_layers}_{dropout}_{batch_size}'\n",
        "            model= torch.load(f'/content/drive/MyDrive/Deep3/{name}')\n",
        "            print(name)\n",
        "            acc,loss = test(valloader, model, loss_fn,name)\n",
        "            dict_acc[name] = acc\n"
      ],
      "metadata": {
        "id": "b6cxPhsRHufp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_by_value = dict(sorted(dict_acc.items(), key=lambda item: item[1],reverse=True))\n",
        "for i in sorted_by_value.items():\n",
        "  print(i)\n"
      ],
      "metadata": {
        "id": "RbVj8PLKNFaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,(k,v) in enumerate(sorted_by_value.items()):\n",
        "  model = k.split('_')[0]\n",
        "  hidden_size = k.split('_')[1]\n",
        "  num_lay = k.split('_')[2]\n",
        "  dropout = k.split('_')[3]\n",
        "  batch_size = k.split('_')[4]\n",
        "  print(f'model: {model}, hidden_size: {hidden_size}, num layers: {num_lay}, dropout: {dropout}, batch_size: {batch_size}\\n\\\n",
        "The accuracy is: {v}\\n\\n')\n",
        "    "
      ],
      "metadata": {
        "id": "6x2KoEHRI7Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "e2WhLZyDjt9s"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
